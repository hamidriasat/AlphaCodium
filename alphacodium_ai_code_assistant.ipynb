{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AI-Powered Code Assistant Agent\n",
    "\n",
    "This notebook presents an AI-powered Code Assistant Agent designed to generate and validate code solutions for programming contest problems through a structured and automated process. The entire process consists of five main steps, ensuring robust and accurate solutions through iterative refinement and validation.\n",
    "\n",
    "**Input**\n",
    "The assistant begins by receiving the problem's name, a detailed problem description, and the number of example test cases.\n",
    "\n",
    "**1. Problem Reflection**\n",
    "The assistant generates a structured reflection on the problem. It creates a comprehensive summary and detailed explanations for each example test case, ensuring a deep understanding before moving forward.\n",
    "\n",
    "**2. Possible Solutions**\n",
    "The assistant generates multiple potential solutions for the problem. It uses structured prompts to interact with AI models, creating distinct solutions that comprehensively address the problem's requirements and constraints.\n",
    "\n",
    "**3. Rank Solutions**\n",
    "The generated solutions are evaluated to select the best one. The assistant assesses each solution's ability to fully solve the problem while maintaining simplicity, robustness, and efficiency.\n",
    "\n",
    "**4. Initial Code Generation**:\n",
    "The assistant transforms the best-ranked solution into executable Python code. It includes necessary imports and organizes the main logic into small, meaningful functions.\n",
    "\n",
    "**5. Iterative Testing and Refinement**:\n",
    "Using LangGraph, the generated code undergoes iterative testing against the provided test cases. The assistant executes the code and compares the results with the expected outputs. If discrepancies arise, the assistant refines the solution, regenerates the code, and retests it. This process continues until a robust and accurate solution is achieved or a maximum number of iterations is reached.\n",
    "\n",
    "**Summary**\n",
    "By following these steps, the AI-powered Code Assistant Agent ensures that the final solution not only meets the problem's requirements but also handles valid inputs effectively, making it reliable for practical implementation.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e59cadf810004b6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://i.ibb.co/wJ0GBBh/Alpha-Codium-Mini-drawio.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a295529173de007a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2f10a86d7e5ddf"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:33:55.178154Z",
     "start_time": "2024-08-05T06:33:55.130843800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input\n",
    "\n",
    "Specifies the input name (`input_problem_name`), its detailed problem description (`input_problem_description`), and the number of test cases it includes (`input_actual_number_of_tests`)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "345c3040e19ecbe6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "input_problem_name = '1575_B. Building an Amusement Park'\n",
    "\n",
    "# TODO: separate public test cases from description, not the input structure details only the input/output examples\n",
    "input_problem_description = \"\"\"\n",
    "Mr. Chanek lives in a city represented as a plane. He wants to build an amusement park in the shape of a circle of radius r. \n",
    "The circle must touch the origin (point (0, 0)).\n",
    "There are n bird habitats that can be a photo spot for the tourists in the park. The i-th bird habitat is at point p_i = (x_i, y_i).\n",
    "\n",
    "Find the minimum radius r of a park with at least k bird habitats inside. \n",
    "\n",
    "A point is considered to be inside the park if and only if the distance between p_i and the center of the park is less than or equal \n",
    "to the radius of the park.\n",
    "Note that the center and the radius of the park do not need to be integers.\n",
    "\n",
    "In this problem, it is guaranteed that the given input always has a solution with r ≤ 2 ⋅ 10^5.\n",
    "\n",
    "Input\n",
    "\n",
    "The first line contains two integers n and k (1 ≤ n ≤ 10^5, 1 ≤ k ≤ n) — the number of bird habitats in the city and the number of bird \n",
    "habitats required to be inside the park.\n",
    "The i-th of the next n lines contains two integers x_i and y_i (0 ≤ |x_i|, |y_i| ≤ 10^5) — the position of the i-th bird habitat.\n",
    "\n",
    "Output\n",
    "\n",
    "Output a single real number r denoting the minimum radius of a park with at least k bird habitats inside. It is guaranteed that the given \n",
    "input always has a solution with r ≤ 2 ⋅ 10^5.\n",
    "Your answer is considered correct if its absolute or relative error does not exceed 10^{-4}.\n",
    "Formally, let your answer be a, and the jury's answer be b. Your answer is accepted if and only if \\frac{|a - b|}{max{(1, |b|)}} ≤ 10^{-4}.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input\n",
    "\n",
    "8 4\n",
    "-3 1\n",
    "-4 4\n",
    "1 5\n",
    "2 2\n",
    "2 -2\n",
    "-2 -4\n",
    "-1 -1\n",
    "-6 0\n",
    "\n",
    "Output\n",
    "\n",
    "3.1622776589\n",
    "\n",
    "\n",
    "Input\n",
    "\n",
    "1 1\n",
    "0 0\n",
    "\n",
    "\n",
    "Output\n",
    "\n",
    "0.0000000000\n",
    "\n",
    "Note\n",
    "\n",
    "In the first example, Mr. Chanek can put the center of the park at (-3, -1) with radius √{10} ≈ 3.162. It can be proven this is the minimum r.\n",
    "\"\"\"\n",
    "\n",
    "input_actual_number_of_tests = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:33:55.178154Z",
     "start_time": "2024-08-05T06:33:55.163640200Z"
    }
   },
   "id": "a808d42d589a00f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem Reflection\n",
    "\n",
    "The aim of the problem reflection section is to deeply understand and document the given problem in a structured manner. This involves creating a self-reflection that captures all aspects of the problem in detailed bullet points, considering nuances, constraints, and examples provided in the problem description. Additionally, this section includes generating detailed explanations for each example test case given in the problem statement, demonstrating how the input leads to the output. This structured reflection helps in forming a solid understanding of the problem before moving on to solution generation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bf5ce9b6cb7cb8c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parser Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5b84857da586b0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Output parser to format reflection output\n",
    "class ReflectionInputOutput(BaseModel):\n",
    "    input: str = Field(description=\"Test input.\")\n",
    "    output: str = Field(description=\"Test output.\")\n",
    "    explanation: str = Field(description=\"Short explanation how the test input leads to the test output.\")\n",
    "\n",
    "\n",
    "class ProblemReflectionParser(BaseModel):\n",
    "    self_reflection: str = Field(\n",
    "        description=\"Describe the problem in your own words, in bullet points. Address the problem goals, inputs, outputs, rules, constraints, and other relevant details.\")\n",
    "    tests_explanations: List[ReflectionInputOutput] = Field(description=\"List of explanations for each test case\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:33:58.106289500Z",
     "start_time": "2024-08-05T06:33:57.977167800Z"
    }
   },
   "id": "96c8aaadba962a3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72c44206e63e8fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# System prompt guiding the reflection process\n",
    "reflection_system_prompt = \"\"\"\n",
    "The self-reflection must cover every aspect of the problem. Pay attention to small details and nuances in the problem description.\n",
    "\"\"\"\n",
    "\n",
    "# User prompt asking for a detailed reflection and test explanations\n",
    "reflection_user_prompt = \"\"\"You are given a code contest problem:\n",
    "\n",
    "problem name: '{name}'\n",
    "\n",
    "\n",
    "problem description:\n",
    "=====\n",
    "{description}\n",
    "=====\n",
    "\n",
    "\n",
    "Given the code contest problem, you have two tasks:\n",
    "1) Reflect on the problem, and describe it in your own words, in bullet points. Pay attention to small details, nuances, notes and examples in the problem description.\n",
    "2) Explain how each provided example input leads to the corresponding output (in total {actual_number_of_tests} examples are provided).\n",
    "Read carefully the problem description. Make sure the test explanations are consistent with them, and between themselves.\n",
    "The explanation must coherently and logically lead from the input to the output. Be as specific as possible.\n",
    "\n",
    "\\n{format_instructions}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:04.347566100Z",
     "start_time": "2024-08-05T06:34:04.317467800Z"
    }
   },
   "id": "2d323e869472f5f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "995280ce6ce0cff2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define model parameters and initialize\n",
    "reflection_temperature = 0.2\n",
    "reflection_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=reflection_temperature, )\n",
    "\n",
    "# Initialize parsers for reflection  output\n",
    "reflection_parser = YamlOutputParser(pydantic_object=ProblemReflectionParser)\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", reflection_system_prompt),\n",
    "        (\"user\", reflection_user_prompt)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Chain to handle prompt-model-parser sequence\n",
    "reflection_chain = reflection_prompt | reflection_model | reflection_parser\n",
    "\n",
    "reflection_testing_prompt = reflection_prompt.format(name=input_problem_name,\n",
    "                                                     description=input_problem_description,\n",
    "                                                     actual_number_of_tests=input_actual_number_of_tests,\n",
    "                                                     format_instructions=reflection_parser.get_format_instructions())\n",
    "# Invoke the chain to produce the reflection output\n",
    "reflection_output: ProblemReflectionParser = reflection_chain.invoke({\"name\": input_problem_name,\n",
    "                                                                      \"description\": input_problem_description,\n",
    "                                                                      \"actual_number_of_tests\": input_actual_number_of_tests,\n",
    "                                                                      \"format_instructions\": reflection_parser.get_format_instructions()\n",
    "                                                                      })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:18.299926500Z",
     "start_time": "2024-08-05T06:34:05.385031Z"
    }
   },
   "id": "8c6d742d01b69695"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Possible Solutions\n",
    "\n",
    "The goal of the possible solutions section is to generate multiple potential solutions to the given problem. This section leverages structured models to represent each solution with details such as the solution name, content, explanation of why it works, relevant labels, and its complexity. Using a combination of system and user prompts, it interacts with a language model to produce up to three distinct solutions, each fully addressing the problem requirements, constraints, and examples. These solutions are designed to be efficient and generalized to handle any valid input within the problem's constraints. This step ensures that various approaches are considered before selecting the most robust and efficient solution."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eec2fe768524e3fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parser Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "867549fcb4792aad"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "class Solution(BaseModel):\n",
    "    name: str = Field(description=\"The name of the solution\")\n",
    "    content: str = Field(description=\"A description of the solution\")\n",
    "    why_it_works: str = Field(\n",
    "        description=\"Shortly explain why this solution correctly solves the problem. Be specific and detailed regarding the problem rules and goals.\")\n",
    "    labels: List[str] = Field(\n",
    "        description=\"A list of labels for the solution. For example (partial list): binary search, dynamic programming, trees, combinatorics, dfs, bfs, graphs, greedy, math, data structures, geometry, number theory, two pointers, simulation, direct approach, probabilities, ...\")\n",
    "    complexity: str = Field(description=\"The complexity of the solution\")\n",
    "\n",
    "\n",
    "class ProblemSolutionsParser(BaseModel):\n",
    "    possible_solutions: List[Solution] = Field(\n",
    "        description=\"A list of possible solutions to the problem. Make sure each solution fully addresses the problem rules and goals.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:26.318362400Z",
     "start_time": "2024-08-05T06:34:26.289768600Z"
    }
   },
   "id": "72f843bd3626c966"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fed61ca8db9d7e0b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "ps_system_prompt = \"\"\"\n",
    "Pay attention to small details and nuances in the problem description.\n",
    "\"\"\"\n",
    "# TODO: Add flexibility to output 1 or 2 solutions too, if only one solution is given then skip solution selection step.\n",
    "ps_user_prompt = \"\"\"You are given a code contest problem, and a self-reflection on the problem:\n",
    "\n",
    "problem description:\n",
    "=====\n",
    "{description}\n",
    "=====\n",
    "\n",
    "\n",
    "self-reflection on the problem:\n",
    "============\n",
    "{self_reflection}\n",
    "============\n",
    "\n",
    "\n",
    "Here are also explanations for the problem test cases:\n",
    "============\n",
    "{tests_explanations_str}\n",
    "============\n",
    "\n",
    "\n",
    "Your goal is to come up with possible solutions to the code contest problem.\n",
    "\n",
    "Guidelines:\n",
    "- Please generate up to a maximum of {max_num_of_possible_solutions} distinct solutions.\n",
    "- Make sure each solution fully addresses the problem goals, constraints, examples, and notes.\n",
    "- Each solution must have reasonable runtime and memory complexity - less than three seconds on a modern computer, given the problem constraints for large inputs.\n",
    "- Double-check the solutions. Each possible solution must be able to generalize to additional test cases, not just the ones provided in the problem description.\n",
    "\n",
    "\\n{format_instructions}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:26.858688200Z",
     "start_time": "2024-08-05T06:34:26.810122600Z"
    }
   },
   "id": "3c43724bc892a28f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def format_reflection_tests(tests: List[ReflectionInputOutput]) -> str:\n",
    "    \"\"\"Formats a list of reflection test cases into a readable string.\"\"\"\n",
    "    formatted = \"\"\n",
    "    for i, test in enumerate(tests, 1):\n",
    "        formatted += f\"Test {i}:\\n\"\n",
    "        formatted += f\"Input:\\n{test.input.strip()}\\n\"\n",
    "        formatted += f\"Output:\\n{test.output.strip()}\\n\"\n",
    "        formatted += f\"Explanation:\\n{test.explanation.strip()}\\n\\n\"\n",
    "    return formatted.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:27.323133600Z",
     "start_time": "2024-08-05T06:34:27.275730600Z"
    }
   },
   "id": "a04bfa5d98259a73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14319cf10fb878bc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "ps_max_num = 3\n",
    "ps_temperature = 0  # 0.3\n",
    "\n",
    "ps_model = ChatOpenAI(model_name=\"gpt-4\", temperature=ps_temperature, )\n",
    "\n",
    "ps_parser = YamlOutputParser(pydantic_object=ProblemSolutionsParser)\n",
    "ps_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ps_system_prompt),\n",
    "        (\"user\", ps_user_prompt)\n",
    "    ],\n",
    ")\n",
    "\n",
    "ps_chain = ps_prompt | ps_model | ps_parser\n",
    "\n",
    "ps_testing_prompt = ps_prompt.format(description=input_problem_description,\n",
    "                                     self_reflection=reflection_output.self_reflection,\n",
    "                                     tests_explanations_str=format_reflection_tests(\n",
    "                                         reflection_output.tests_explanations),\n",
    "                                     max_num_of_possible_solutions=ps_max_num,\n",
    "                                     format_instructions=ps_parser.get_format_instructions())\n",
    "ps_output: ProblemSolutionsParser = ps_chain.invoke({\"description\": input_problem_description,\n",
    "                                                     \"self_reflection\": reflection_output.self_reflection,\n",
    "                                                     \"tests_explanations_str\": format_reflection_tests(\n",
    "                                                         reflection_output.tests_explanations),\n",
    "                                                     \"max_num_of_possible_solutions\": ps_max_num,\n",
    "                                                     \"format_instructions\": ps_parser.get_format_instructions()\n",
    "                                                     })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:34:58.931972400Z",
     "start_time": "2024-08-05T06:34:28.632425300Z"
    }
   },
   "id": "d99aeeb017ae5dee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rank Solutions\n",
    "\n",
    "The rank solutions section is dedicated to evaluating and selecting the best among the generated potential solutions. This involves analyzing each solution to ensure it fully solves the problem while being simple, robust, and efficient. The process uses structured models to capture the selected solution's name, content, the rationale for its selection, and relevant test cases. System and user prompts guide a language model to rank the solutions based on their effectiveness and compliance with problem constraints. The ultimate goal is to pick a solution that is not just theoretically sound but also practically implementable within acceptable runtime and memory constraints."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4694f0ae64deac8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parser Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9155fba69e9ae57e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "class ProblemSolutionTest(BaseModel):\n",
    "    input: str = Field(description=\"Test input.\")\n",
    "    output: str = Field(description=\"Test output.\")\n",
    "\n",
    "\n",
    "class ProblemSolutionParser(BaseModel):\n",
    "    name: str = Field(description=\"The name of the best solution\")\n",
    "    content: str = Field(description=\"The content of the best solution\")\n",
    "    why: str = Field(description=\"Shortly explain why is this the best solution\")\n",
    "    # TODO: Add support for below fields\n",
    "    # flow: list[str] = Field(description=\"Describe the flow of the solution in single-level bullet points. Nested bullet points are not allowed. Each item should be a single bullet point at the same level.\")\n",
    "    problem_tests: List[ProblemSolutionTest] = Field(\n",
    "        \"List the input-output examples that are provided in the problem description.\")\n",
    "    # input_output_examples_flow: List[str] = Field(description=\"Describe, in single-level bullet points, how the proposed flow will lead to getting the expected output for the provided input examples. Nested bullet points are not allowed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:03.335754100Z",
     "start_time": "2024-08-05T06:35:03.272110500Z"
    }
   },
   "id": "8e07e51d9f01d1e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61bcbc6f635538d3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "rs_system_prompt = \"\"\"\n",
    "The decision-making process must be rigorous, taking every detail of the problem description into account.\n",
    "\"\"\"\n",
    "\n",
    "rs_user_prompt = \"\"\"\n",
    "You are given a code contest problem, and a self-reflection on the problem:\n",
    "\n",
    "\n",
    "problem description:\n",
    "=======\n",
    "{description}\n",
    "=======\n",
    "\n",
    "\n",
    "self-reflection on the problem:\n",
    "=======\n",
    "{self_reflection}\n",
    "=======\n",
    "\n",
    "\n",
    "Here is a list of {possible_solutions_length} possible solutions to the problem:\n",
    "=======\n",
    "{possible_solutions_str}\n",
    "=======\n",
    "\n",
    "\n",
    "Using the inputs above, your goal is to choose the best solution to the code contest problem.\n",
    "Don't just pick the most efficient solution. The main consideration is that the solution can fully solve the problem in a simple and robust manner.\n",
    "Make sure the chosen solution has a reasonable runtime - less than three seconds on a modern computer, given the problem constraints regarding large inputs.      \n",
    "        \n",
    "\\n{format_instructions}\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:04.794370300Z",
     "start_time": "2024-08-05T06:35:04.718235300Z"
    }
   },
   "id": "f194b2f0273acf30"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def format_possible_solutions(solutions: List[Solution]) -> str:\n",
    "    \"\"\"Formats a list of Possible Solution objects into a readable string.\"\"\"\n",
    "    formatted = \"\"\n",
    "    for i, solution in enumerate(solutions, 1):\n",
    "        formatted += f\"Solution {i}:\\n\"\n",
    "        formatted += f\"Name: {solution.name}\\n\"\n",
    "        formatted += f\"Content: {solution.content.strip()}\\n\"\n",
    "        formatted += f\"Why it works: {solution.why_it_works.strip()}\\n\"\n",
    "        formatted += f\"Labels: {', '.join(solution.labels)}\\n\"\n",
    "        formatted += f\"Complexity: {solution.complexity}\\n\\n\"\n",
    "    return formatted.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:15.137378500Z",
     "start_time": "2024-08-05T06:35:15.104620100Z"
    }
   },
   "id": "18bd28da329155dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b3921028977f99d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "rs_temperature = 0.2\n",
    "\n",
    "rs_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=rs_temperature, )\n",
    "\n",
    "rs_parser = YamlOutputParser(pydantic_object=ProblemSolutionParser)\n",
    "rs_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rs_system_prompt),\n",
    "        (\"user\", rs_user_prompt)\n",
    "    ],\n",
    ")\n",
    "\n",
    "rs_chain = rs_prompt | rs_model | rs_parser\n",
    "\n",
    "rs_testing_prompt = rs_prompt.format(description=input_problem_description,\n",
    "                                     self_reflection=reflection_output.self_reflection,\n",
    "                                     possible_solutions_length=len(ps_output.possible_solutions),\n",
    "                                     possible_solutions_str=format_possible_solutions(ps_output.possible_solutions),\n",
    "                                     format_instructions=rs_parser.get_format_instructions())\n",
    "\n",
    "rs_output: ProblemSolutionParser = rs_chain.invoke({\"description\": input_problem_description,\n",
    "                                                    \"self_reflection\": reflection_output.self_reflection,\n",
    "                                                    \"possible_solutions_length\": len(ps_output.possible_solutions),\n",
    "                                                    \"possible_solutions_str\": format_possible_solutions(\n",
    "                                                        ps_output.possible_solutions),\n",
    "                                                    \"format_instructions\": rs_parser.get_format_instructions()\n",
    "                                                    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:20.744921Z",
     "start_time": "2024-08-05T06:35:15.922629300Z"
    }
   },
   "id": "53245d4a00e1547e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "def format_best_ranked_solution(selected_solution: ProblemSolutionParser) -> str:\n",
    "    \"\"\"Formats best selected solution into a readable string.\"\"\"\n",
    "    formatted = \"\"\n",
    "    formatted += f\"Name {selected_solution.name}:\\n\"\n",
    "    formatted += f\"Description:\\n{selected_solution.content.strip()}\\n\"\n",
    "    formatted += f\"Reason:\\n{selected_solution.why.strip()}\\n\"\n",
    "    return formatted.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:22.077570Z",
     "start_time": "2024-08-05T06:35:22.046209Z"
    }
   },
   "id": "ed9af1357ea5102a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Code Generation\n",
    "\n",
    "\n",
    "The initial code generation section's primary aim is to transform the best-ranked solution into executable Python code. Using structured output, this section first generates an initial code, including necessary imports and the main code logic, which is organized into small, meaningful functions. Initially, an executable code is generated based on the selected solution."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdc270f4b43d2370"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parser Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77d29c5b8f312b1f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class CodeGenerationParser(BaseModel):\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:23.754691Z",
     "start_time": "2024-08-05T06:35:23.692199200Z"
    }
   },
   "id": "1edc98edef3d5ea1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16325e6c7b152717"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "cg_system_prompt = \"\"\"\n",
    "- You must divide the generated code into small sub-functions, with meaningful names and functionality. Each function should be no longer than 10 lines of code.\n",
    "- Double-check the solution code. The generated solution must generalize to any valid input, and not just the provided examples.\n",
    "- Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block.\n",
    "\"\"\"\n",
    "\n",
    "code_question = \"\"\"\n",
    "You are given a code contest problem, and a self-reflection on the problem.\n",
    "\n",
    "problem description:\n",
    "=============\n",
    "{description}\n",
    "=============\n",
    "\n",
    "\n",
    "self-reflection on the problem:\n",
    "======\n",
    "{self_reflection}\n",
    "======\n",
    "\n",
    "\n",
    "Your goal is to generate a valid Python code that correctly solves the code contest problem, using the following algorithm:\n",
    "=============\n",
    "{s_best_solution}\n",
    "=============\n",
    "\n",
    "\n",
    "Guidelines:\n",
    "- You must divide the generated code into small sub-functions, with meaningful names and functionality. Variables names should also be meaningful.\n",
    "- Double-check the generated code. It should generalize to any valid input, and not just the provided examples.\n",
    "- Make sure to include all the necessary module imports, properly initialize the variables, and address the problem constraints.\n",
    "\n",
    "- The code needs to be self-contained, and executable as-is.\n",
    "\n",
    "The generated code must follow this structure:\n",
    "```\n",
    "def f1(...):\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "def f2(...):\n",
    "    ...\n",
    "    return ...\n",
    "...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input = sys.stdin.read()\n",
    "    ...\n",
    "```\n",
    "The code should read the input using the 'sys.stdin.read()' method. Make sure to properly parse the input, according to the problem description.\n",
    "The output should be printed without additional words using the 'print()' method.\n",
    "\n",
    "\n",
    "\n",
    "\\n{format_instructions}\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:24.857223Z",
     "start_time": "2024-08-05T06:35:24.782005700Z"
    }
   },
   "id": "7664284658f8132d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e691f12f54ce0469"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "cg_temperature = 0.3\n",
    "\n",
    "cg_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=cg_temperature, )\n",
    "\n",
    "cg_parser = YamlOutputParser(pydantic_object=CodeGenerationParser)\n",
    "cg_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", cg_system_prompt),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "cg_chain = cg_prompt | cg_model | cg_parser\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:27.235043900Z",
     "start_time": "2024-08-05T06:35:26.107235600Z"
    }
   },
   "id": "465774631a6f0324"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "question = code_question.format(description=input_problem_description,\n",
    "                                self_reflection=reflection_output.self_reflection,\n",
    "                                s_best_solution=format_best_ranked_solution(rs_output),\n",
    "                                format_instructions=cg_parser.get_format_instructions()\n",
    "                                )\n",
    "messages = [(\"user\", question)]\n",
    "\n",
    "cg_output: CodeGenerationParser = cg_chain.invoke({\"messages\": messages})\n",
    "\n",
    "# cg_output.code = cg_output.code[:-50]  # For testing, truncate the code "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:36.822988500Z",
     "start_time": "2024-08-05T06:35:30.843275300Z"
    }
   },
   "id": "a39a8e391cf5032e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iterative Testing and Refinement\n",
    "\n",
    "\n",
    "The process doesn't end with the initial code generation. Using LangGraph in Iterative Testing and Refinement section, the code is then iteratively tested against the provided test cases. During these iterative checks, the script executes the code and compares the generated output with the expected output for each test case. If the code fails to produce the correct output, it prompts the system to reflect, adjust, and generate a new solution, which is then tested again. This iterative process continues until a correct and robust solution is found or a maximum number of iterations is reached. This ensures that the final code not only meets the problem requirements but is also practically implementable and reliable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9623ac07300033f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### State"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9981466b075e88a2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error (str): Binary flag for control flow to indicate whether a test error occurred.\n",
    "        messages (list of AnyMessage): Contains user questions, error messages, and reasoning.\n",
    "        generation (CodeGenerationParser): Code solution generated.\n",
    "        iterations (int): Number of attempts made.\n",
    "        problem_input_output (ReflectionInputOutput): Details of the problem's input and output.\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    generation: CodeGenerationParser\n",
    "    iterations: int\n",
    "    problem_input_output: ReflectionInputOutput"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:38.794975300Z",
     "start_time": "2024-08-05T06:35:38.452173800Z"
    }
   },
   "id": "68de3f2ecb1b39a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nodes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbe63550c51066f9"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import uuid\n",
    "\n",
    "### Parameters\n",
    "max_iterations = 3\n",
    "\n",
    "\n",
    "### Nodes\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updated state with generated code.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Generating code solution...\")\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = cg_chain.invoke({\"messages\": messages})\n",
    "    messages = [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            # f\"Here is my attempt to solve the problem....\"\n",
    "            f\"Prefix:\\n{cg_output.prefix} \\nImports:\\n{cg_output.imports} \\nCode:\\n{cg_output.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Checking code solution...\")\n",
    "\n",
    "    # State\n",
    "    code_solution = state[\"generation\"]\n",
    "    problem_input_output = state[\"problem_input_output\"]\n",
    "\n",
    "    # Get solution components\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check code execution with input and expected output\n",
    "    try:\n",
    "        combined_code = f\"{imports}\\n{code}\"\n",
    "        print(\"Executing code with provided input and capturing output...\")\n",
    "\n",
    "        # Save the original stdin and stdout\n",
    "        original_stdin = sys.stdin\n",
    "        original_stdout = sys.stdout\n",
    "\n",
    "        # Passing input\n",
    "        sys.stdin = io.StringIO(problem_input_output.input)\n",
    "\n",
    "        # Redirect sys.stdout to capture the output\n",
    "        output_capture = io.StringIO()\n",
    "        sys.stdout = output_capture\n",
    "\n",
    "        exec(combined_code, globals())  # Execute the combined code\n",
    "\n",
    "        # Get the captured output\n",
    "        output = output_capture.getvalue().strip()\n",
    "\n",
    "        # Restore original stdin and stdout\n",
    "        sys.stdin = original_stdin\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "        if output[:5] != problem_input_output.output[:5]:\n",
    "            print(\n",
    "                f\"Failed to generate expected output.\\nActual output: {output} Generated output: {problem_input_output.output}\")\n",
    "            error_message = [\n",
    "                (\n",
    "                    \"user\",\n",
    "                    f\"Your solution failed to generate expected output.\\nPassed input: {problem_input_output.input} \\nCode output:{output} \\nExpected output: {problem_input_output.output} \\nReflect on this why the code has failed to generated expected output. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "                )\n",
    "            ]\n",
    "            return {\n",
    "                \"messages\": error_message,\n",
    "                \"error\": \"yes\",\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Restore original stdin and stdout\n",
    "        sys.stdin = original_stdin\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "        print(f\"Error executing the code. \\n{e}\")\n",
    "        error_message = [\n",
    "            (\n",
    "                \"user\",\n",
    "                f\"Your solution failed the code execution test with following error: '{e}') with following input '{problem_input_output.input}'. \\nReflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "            )\n",
    "        ]\n",
    "        return {\n",
    "            \"messages\": error_message,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors found\n",
    "    print(\"Code executed successfully without any errors.\")\n",
    "    return {\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "### Conditional edges\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations >= max_iterations:\n",
    "        print(\"Decision: Finish\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"Decision: Retry solution\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "### Utilities\n",
    "def _print_event(event: dict, _printed: set, max_length=150):\n",
    "    \"\"\"\n",
    "    Utility function to print events\n",
    "\n",
    "    Args:\n",
    "        event (dict): The event to print\n",
    "        _printed (set): Set of printed message IDs\n",
    "        max_length (int): Maximum length of the printed message\n",
    "    \"\"\"\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    _messages = event.get(\"messages\")\n",
    "    if _messages and isinstance(_messages, list):\n",
    "        for message in _messages:\n",
    "            if message.id not in _printed:\n",
    "                msg_repr = message.pretty_repr(html=True)\n",
    "                if len(msg_repr) > max_length:\n",
    "                    msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "                print(msg_repr)\n",
    "                _printed.add(message.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:38.905286700Z",
     "start_time": "2024-08-05T06:35:38.858191200Z"
    }
   },
   "id": "66a55af81e6170b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19046cfb782fc05d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "builder.add_node(\"check_code\", code_check)  # check code\n",
    "builder.add_node(\"generate\", generate)  # generation solution\n",
    "\n",
    "# Build graph\n",
    "builder.add_edge(START, \"check_code\")\n",
    "builder.add_edge(\"generate\", \"check_code\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:39.237974100Z",
     "start_time": "2024-08-05T06:35:39.170620800Z"
    }
   },
   "id": "67c842284d0cd30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b79e3c57e4e21492"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:41.076426100Z",
     "start_time": "2024-08-05T06:35:39.495520700Z"
    }
   },
   "id": "46969abd000fab43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33ebda688754f73b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Test case 1\n",
      "********************\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "\n",
      "You are given a code contest problem, and a self-reflection ... (truncated)\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Prefix:\n",
      "The problem involves building a circular amusement p ... (truncated)\n",
      "Checking code solution...\n",
      "Executing code with provided input and capturing output...\n",
      "Code executed successfully without any errors.\n",
      "Decision: Finish\n",
      "Code is correct. Updating code solution.\n",
      "********************\n",
      "Test case 2\n",
      "********************\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "\n",
      "You are given a code contest problem, and a self-reflection ... (truncated)\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Prefix:\n",
      "The problem involves building a circular amusement p ... (truncated)\n",
      "Checking code solution...\n",
      "Executing code with provided input and capturing output...\n",
      "Code executed successfully without any errors.\n",
      "Decision: Finish\n",
      "Code is correct. Updating code solution.\n"
     ]
    }
   ],
   "source": [
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "question = code_question.format(description=input_problem_description,\n",
    "                                self_reflection=reflection_output.self_reflection,\n",
    "                                s_best_solution=format_best_ranked_solution(rs_output),\n",
    "                                format_instructions=cg_parser.get_format_instructions()\n",
    "                                )\n",
    "\n",
    "for i, problem_test in enumerate(reflection_output.tests_explanations):\n",
    "    print(\"*\" * 20)\n",
    "    print(f\"Test case {i + 1}\")\n",
    "    print(\"*\" * 20)\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": f\"thread_id_{i + 1}\",  # Checkpoints are accessed by thread_id\n",
    "        }\n",
    "    }\n",
    "\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [\n",
    "            (\"user\", question),\n",
    "            (\n",
    "                \"assistant\",\n",
    "                f\"Prefix:\\n{cg_output.prefix} \\nImports:\\n{cg_output.imports} \\nCode:\\n{cg_output.code}\",\n",
    "            )\n",
    "        ],\n",
    "            \"generation\": cg_output,\n",
    "            \"problem_input_output\": problem_test,\n",
    "            \"iterations\": 0\n",
    "        }\n",
    "        , config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "\n",
    "    if event['error'] == \"no\":  # Solution was either working or after update its working\n",
    "        print(\"Code is correct. Updating code solution.\")\n",
    "        cg_output: CodeGenerationParser = event['generation']  # Updating working code\n",
    "    else:\n",
    "        print(\"Failed to generate code. Skipping code update.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T06:35:41.170647300Z",
     "start_time": "2024-08-05T06:35:41.092057700Z"
    }
   },
   "id": "89ab7daf87f09ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Generated Code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d041f96b59bc1cc"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "import math\n",
      "from heapq import nsmallest\n",
      "\n",
      "def read_input():\n",
      "    input = sys.stdin.read()\n",
      "    data = input.split()\n",
      "    n = int(data[0])\n",
      "    k = int(data[1])\n",
      "    coordinates = [(int(data[i * 2 + 2]), int(data[i * 2 + 3])) for i in range(n)]\n",
      "    return n, k, coordinates\n",
      "\n",
      "def calculate_distances(coordinates):\n",
      "    return [math.sqrt(x**2 + y**2) for x, y in coordinates]\n",
      "\n",
      "def find_kth_smallest_distance(distances, k):\n",
      "    return nsmallest(k, distances)[-1]\n",
      "\n",
      "def main():\n",
      "    n, k, coordinates = read_input()\n",
      "    distances = calculate_distances(coordinates)\n",
      "    min_radius = find_kth_smallest_distance(distances, k)\n",
      "    print(f\"{min_radius:.10f}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "final_code = f\"{cg_output.imports}\\n{cg_output.code}\"\n",
    "print(final_code)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T09:31:04.647910200Z",
     "start_time": "2024-08-05T09:31:04.617560500Z"
    }
   },
   "id": "f236517777a4622b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "420c1ef306638ed1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
